---
title: "SHINYREPS_PROJECT"
output:
  html_document:
    toc: true
    toc_float: true
    css: styles.css
---

<div class="contentbox">


# Description

Enter project description here


# Processing

	1. bpipe call: bpipe run marsseq.pipeline.groovy rawdata/*.fastq.gz
	2. bpipe command: run { "%.fastq.gz" *  [ FastQC ] + "%.R*.fastq.gz" * [ AddUMIBarcodeToFastq + Cutadapt + FastQC + STAR + BAMindexer + 
[ subread_count + BAMindexer + umicount , bam2bw , inferexperiment , subread2rnatypes, geneBodyCov2 ]] + collectBpipeLogs + shinyReports


```{r setup, echo=F, result='hide', error=F, warning=F, message=F}

# source helper functions
source("DE.shinyrep.helpers.R")

# load required packages
attach_packages(c("rmarkdown", "knitr", "Cairo", "gplots", "ggplot2", "plotly", "RColorBrewer", "ggrepel", "parallel",
                  "grid", "gridExtra", "rtracklayer", "scater", "scran", "ggbeeswarm", "dplyr", "tidyr", "forcats",
                  "scales", "kableExtra", "reshape2", "M3Drop", "vipor", "corrplot", "limma", "pheatmap",
                  "VennDiagram", "edgeR", "DESeq2", "GeneOverlap", "viridis", "Biobase"))

# load global variables
loadGlobalVars(f="shinyReports.txt")

# define type of scRNA-Seq (currently: "MARSseq", "SmartSeq2")
seqtype = "MARSseq"
useSpikein = NULL # e.g. "ERCC" or NULL

# set options
options(stringsAsFactors=FALSE)
CORES <- 2
pal   <- brewer.pal(9, "Set1")
pal_rb <- colorRampPalette(c(pal[1], "white", pal[2]))(20)
pal_y  <- colorRampPalette(c("black", "yellow"))(100)

knitr::opts_chunk$set(cache=F,
                      echo=F,
                      warning=F,
                      message=F,
                      dev='CairoPNG')

theme_set(theme_bw() + theme(axis.text=element_text(colour="grey30",size=12),
									axis.title=element_text(colour="grey30",size=14),
									plot.title=element_text(size=14,hjust=0.5),
									plot.subtitle=element_text(size=12,hjust=0.5),
									legend.text=element_text(size=12,colour="grey30"),
									legend.title=element_text(size=12,colour="grey30")))

# load list of mitochondrial genes
mito.genes <- read.delim(paste0(SHINYREPS_PROJECT,"/mouse_mito_genes_Ensembl.txt"))[, 1]


## load targets file for all cells. Columns required: "sample", "barcode", "row", "col", "cells", "group"
targets <- read.delim("../targets.txt", sep=",")
# targets <- read.delim(SHINYREPS_TARGET)
group.vars <- colnames(targets)[!colnames(targets) %in% c("sample", "barcode", "row", "col")] 
targets[,group.vars] <- lapply(targets[,group.vars], factor)

```

```{r read_annotation, cache=TRUE}
# load gene annotation provided in essential.vars.groovy
gtf <- import.gff(SHINYREPS_GTF, format="gtf", feature.type="exon")
gtf.flat <- unlist(reduce(split(gtf, elementMetadata(gtf)$gene_id)))
gene.lengths <- tapply(width(gtf.flat), names(gtf.flat), sum)
gene.names <- unique(as.data.frame(gtf)[, c("gene_id", "gene_name")])

```


# Quality control on bulk RNA

## FastQC of all reads 

The raw sequence reads of all samples are analysed with the popular FastQC tool (http://www.bioinformatics.babraham.ac.uk/projects/fastqc/).

1. The "Read qualities" Box-Whisker plots show the range of quality values across all base positions:
    (i) The central red line is the median value,
    (ii) The yellow box represents the inter-quartile range (25-75%),
    (iii) The upper and lower whiskers represent the 10% and 90% points,
    (iv) The blue line represents the mean quality.
The y-axis on the graph shows the Phred quality scores, which are logarithmically related to the base-calling error probabilities. The higher the score the better the base call. The background of the graph divides the y axis into very good quality calls (green), calls of reasonable quality (orange), and calls of poor quality (red). Typically, the majority of calls on all base positions fall into the green area.

2. The "Sequence bias" plots show the proportion of each base (% G, A, T and C) at each position. In a random library there would be little difference between the positions of a sequence run, so the lines in this plot should run parallel with each other. But most RNA-seq libraries show sequence imbalance in the first 10-12 read positions due to RT priming biases, which should however look fairly similar in all samples.

3. The "GC Content" plots show the GC% distribution of all reads (red lines) and the ideal normal distribution based on the data (blue lines). Typically, the red and blue lines tightly overlap and look essentially the same in all samples. An unusually shaped distribution could indicate a contaminated library.

```{r FastQC_paragraph1, echo=F, results='asis', error=F, warning=F, message=F}
##### parameters to set:
# Select samples for which you would like to include fastqc results in the report. For single cell RNA-Seq with many cells, 
# you may want to restrict the total number of plots. If you provide a regular expression in 'samplePattern' only those 
# filenames will be included which match this expression, e.g. setting samplePattern="R1" yields only those fastq 
# files containing read1 of a read pair. This is recomended e.g. for MARS-Seq, where Read2 contains barcode information only.
# For samplePattern=NULL (default) all fastq files will be included.
# If you want to exclude samples according to the given certain pattern (instead of including), set exclude=T. 
# This is e.g. for excluding the trimmed fastq files which contain "cutadapt" in the file name (see below). 
# If you set argument 'maxno', the maximum sample number will be restricted accordingly to the first 'maxno' plots. 
samplePattern="R1"
excludePattern=F  # default FALSE
maxno=NULL # default NULL
##### 

cat(DEhelper.Fastqc(web=F, samplePattern=samplePattern, exclude=excludePattern, maxno=maxno), sep="\n")
# These options also apply for the helper functions following below
```


## Adapter trimming with Cutadapt

The following plot shows the amount of reads trimmed for the selected adapter sequences as well as polyA/polyT sequences. Additionally, it shows the amount of reads removed due to a length of less than 30 bases after trimming.

```{r cutadapt, echo=F, results='asis', error=F, warning=F, message=F}
##### parameters to set:
# define subset of cutadapt log files if desired (samplePattern=NULL (default) includes all files).
samplePattern=NULL
# define categories of targets.txt to be used for dot color in the plot (one plot per element of colorByFactor will be created). 
# The function will try to map the data from targets$sample to the cutadapt log file names (for this, the unique part of 
# targets$sample must be a substring of file name). If you have cutadapt log files from pooled fastq files but cell-wise 
# information in targets.txt as in MARS-Seq, you may provide another customized targets object in 'targetsdf'. 
# Otherwise pruned file names will be used by default.
colorByFactor = NULL # NULL by default
targetsdf=targets
#####

DEhelper.cutadapt(samplePattern=samplePattern, colorByFactor=colorByFactor, targetsdf=targetsdf)
```


## FastQC after adapter trimming

Quality control plots of fastq files after adapter trimming with cutadapt.

```{r FastQC_paragraph2, echo=F, results='asis', error=F, warning=F, message=F}
# Applying FastQC again after adapter trimming (fastq file names contain "cutadapt" as part of their name)

cat(DEhelper.Fastqc(web=F, samplePattern="cutadapt"), sep="\n") 
```


## Gene body coverage ##

The plots below show meta-gene profiles of 5' to 3' read coverage and can reveal biases due to RNA degradation or specific library prep protocol; polyA-selection protocols are particularly prone of producing 3' coverage bias upon RNA degradation. The grey line depicts the actual read coverage and the red line shows the overall trend.

```{r GeneBodyCoverage_paragraph, echo=F, results='asis', error=F, warning=F, message=F}
cat(DEhelper.geneBodyCov(web=F), sep="\n")
```

## Strand specificity ##

The table below shows the fraction of reads mapped in sense or antisense to gene exons - around 0.5 for non-stranded library prep protocols and close to 0 or 1 for strand-specific RNA-seq protocols.

```{r echo=F, results='asis', error=F, warning=F, message=F}
cat(DEhelper.strandspecificity(), sep="\n")
```

## RNA class representation ##

The following plot shows the fraction of reads assigned to various RNA classes. These plots help in determining if the sample prep protocol worked well and may reveal issues with rRNA contamination. 

```{r RNAtypes_paragraph, echo=F, results='asis', error=F, warning=F, message=F}
DEhelper.RNAtypes()
```



# Mapping Statistics

apping to the reference genome & transcriptome is performed with STAR (https://github.com/alexdobin/STAR). The program version, genome assembly and software parameters are described in the table at the end of the report.

The mapping statistics below show the number and percentage of: (i) input raw reads, (ii) uniquely mapped reads, (iii) multi-mapped reads aligning equally well to multiple (up to 20) positions in the genome, (iv) reads that align to too many (>20) genome loci are discarded, (v) unmapped reads. For the multimapped reads, one random alignment among the best mapping positions is retained. 

While both unique and multi-mapped reads are included in the generation of browser coverage tracks, only uniquely mapped reads are typically taken into account in the differential expression analysis in order to avoid potential false-positives. However, this standard analysis approach may also exclude some recently duplicated genes or gene-pseudogene pairs, resulting in false-negatives. To investigate the potential expression changes in such genes, a side branch of DESeq2 may be used for using all mapped reads.

The browser tracks are generated using bamCoverage tool in [deepTools](https://deeptools.readthedocs.io/en/develop/) and they are normalized using the Counts Per Million mapped reads (CPM) method. The CPM formula is: CPM  = number of reads per bin (20 bp) / number of mapped reads (in millions).

```{r mapping_stats, fig.height=10, fig.width=12, results='asis', message=FALSE, warning=FALSE}
##### parameters to set:
# define subset of Star log files if desired. samplePattern=NULL (default) includes all files.
samplePattern=NULL
# define categories of targets.txt to be used for dot color in the summary plot (one plot per element of colorByFactor will be created). 
# The function will try to map the data from targets$sample to the cutadapt log file names (for this, the unique part of 
# targets$sample must be a substring of file name). If you have cutadapt log files from pooled fastq files but cell-wise 
# information in targets.txt as in MARS-Seq, you may provide another customized targets object in 'targetsdf'. 
# Otherwise pruned file names will be used by default.
colorByFactor = NULL # NULL by default
targetsdf=targets
#####

DEhelper.STAR(samplePattern=samplePattern, targetsdf=targetsdf, colorByFactor=colorByFactor)
```


## Read de-duplication and counting with UMI-tools

UMI-tools counts the mapped reads obtained after de-duplication. As input UMI-tools uses the uniquely mapped reads from STAR as well as as the multimapped reads (but not those which are mapped to too many loci).

```{r umicount, echo=F, results='asis', error=F, warning=F, message=F}
##### parameters to set:
# define subset of umicount log files if desired (samplePattern=NULL (default) includes all files).
samplePattern=NULL
# define categories of targets.txt to be used for dot color in the plot (one plot per element of colorByFactor will be created). 
# The function will try to map the data from targets$sample to the umicount log file names (for this, the unique part of 
# targets$sample must be a substring of the file name). If you have umi-tools log files from pooled fastq files but cell-wise 
# information in targets.txt as in MARS-Seq, you may provide another customized targets object in 'targetsdf'. 
# Otherwise pruned file names will be used by default.
colorByFactor = NULL # NULL by default
targetsdf=targets
#####

DEhelper.umicount(samplePattern=samplePattern, colorByFactor=colorByFactor, targetsdf=targetsdf)
```







# Low-level analysis of single-cell RNAseq data

The analysis workflow is based on the Bioconductor package *scater* and the Bioconductor workshop published in F1000 Research: Lun, A. T. L., McCarthy, D. J., & Marioni, J. C. (2016). *A step-by-step workflow for low-level analysis of single-cell RNA-seq data.* F1000Research, 5(0), 2122. http://doi.org/10.12688/f1000research.9501.1


```{r loading_counts, echo=F, message=FALSE, error=TRUE, warning=TRUE, cache=TRUE}

## load counts for MARSseq design (pooled count files) 
if(seqtype == "MARSseq") {

# load counts
f <- list.files(paste0(SHINYREPS_PROJECT,"/results/umicount"), pattern="\\.tsv$", full.names=TRUE)
counts <- mclapply(f, read.delim, head=T, row.names=1, mc.cores=CORES)
names(counts) <- basename(f)

# pool-wise replacement of barcodes by sample names. A pool consists of those cells which are amplified together 
# in one pool (i.e. all reads have identical pool barcode) but which all have different unique cell barcodes.
# The cell barcodes are re-used in other pools. For assignment of cell barcodes given in 'targets.txt' to the 
# pooled count data, the pool ID given in 'targets.txt' must be a substring of the respective count data filename
# (no matter at which position).
  for (i in unique(targets$pool)) {
   if(sum(grepl(i, names(counts), ignore.case = T)) !=1) {stop("\ncannot unambiguously assign pool ID given in targets.txt to count filename")}
   targets_pool <- targets[targets$pool ==i, ]
   countname <- grep(i, names(counts), ignore.case = T, value=T )
   colnames(counts[[countname]]) <- targets_pool[match(colnames(counts[[countname]]), targets_pool$barcode), "sample"]
   }
  
  # merge pools into one dataset with union of genelists
  custom.merge <- function(x,y) { # custom merge function for Reduce
      z <- merge(x,y, all=T, by="row.names")
      rownames(z) <- z$Row.names
      return(z[,-1])}
  counts <- Reduce(custom.merge, counts)
  
  counts[is.na(counts)] <- 0 # set NAs in the dataset to zero counts
  targets <- targets[targets$sample %in% colnames(counts),] # adjust targets in case of cells have been lost during processing
  counts <- counts[,match(targets$sample, colnames(counts))] # sort counts according to target
  # table(colnames(counts) == targets$sample) # all TRUE

} # end load counts for MARSseq design


#### create SingleCellExperiment object
sce <- SingleCellExperiment(assays=list(counts=as.matrix(counts)), colData = targets)

# add gene symbols from annotation file to SingleCellExperiment object
rowData(sce)$ENSEMBL <- rownames(sce)
rowData(sce)$SYMBOL  <- gtf$gene_name[match(rownames(sce), gtf$gene_id)]

# get rid of NAs and duplicated names (missing SYMBOLS are replaced with ENSEMBL IDs)
new.names <- rowData(sce)$SYMBOL
missing.name <- is.na(rowData(sce)$SYMBOL)
new.names[missing.name] <- rowData(sce)$ENSEMBL[missing.name]

# duplicated names are extended with ENSEMBL IDs
dup.name <- new.names %in% new.names[duplicated(new.names)]
new.names[dup.name] <- paste0(new.names, "_", rowData(sce)$ENSEMBL)[dup.name]
rowData(sce)$SYMBOL <- new.names

# add gene length information
rowData(sce)$genelength <- gene.lengths[ match(rownames(sce),names(gene.lengths)) ]

```


## Quality control of cells and RNA sequenced

To assess if the sequenced libraries are usable and the RNA captured represents a meaningful fraction of the RNA present in the cell, we are focussing on the following factors:

* **Library size:** for cells with small library size the RNA was not efficiently captured.
* **Number of expressed genes:** few expressed genes suggest that a diverse transcript population was not captured.
* **Proportion of reads mapping to mitochondrial genes:** high proportion mean increased apoptosis and/or loss of cytoplasmatic RNA from lysed cells.

To remove outliers, these criteria may be filtered either for relative thresholds using the median absolute deviation (MAD) or by setting absolute threshold after inspecting the quality control plots.

```{r quality_plots_of_cells}

##### parameters to set:
# define set of categories used to annotate cells in the plots (e.g.: annoFactors <- c("group", "pool"))
# By default, all columns given in 'targets.txt' ar used except for "sample", "barcode", "row" and "col".
annoFactors <- group.vars # default is group.vars
# set NMADS to be indicated in the plots as dashed line (no filtering applied yet)
NMADS=2 
#####

if(!exists("sce.noQCmetrics")) {sce.noQCmetrics <- sce} # store unmodified sce

# define mitochondrial genes as control features
is.mito  <- row.names(sce) %in% mito.genes
# calculate QC metrics
sce <- calculateQCMetrics(sce, feature_controls=list(Mt=is.mito)) # Mt=is.mito, Rb=is.ribosomal
qc.frame <- colData(sce)
qc.frame$Lib.size <- sce$total_counts/1e3 # library size in thousands
qc.frame <- as.data.frame(qc.frame)

# generate plots for Lib.size, total_features, pct_amount_Mt for each selected category 
# histograms
qc.plots <- lapply(c("Lib.size", "total_features_by_counts", "pct_counts_Mt"), function(to.plot){ 
      if(to.plot=="Lib.size"){
        xlabel="Lib. sizes in thousands"
         }else{
           xlabel=to.plot}
  
      if(to.plot=="pct_counts_Mt"){
        madOrient="high"
      }else{
        madOrient="low"}

  plot.list <- lapply(annoFactors, function(separation){
      p <- ggplot(qc.frame, aes_string(to.plot, fill=separation))+ 
            geom_histogram(position="identity", alpha=0.5, bins=100, col="grey80") +
            geom_vline(aes(xintercept = median(na.omit(qc.frame[,to.plot])), col="median"), linetype=2)  +
            geom_vline(aes(xintercept = MAD(na.omit(qc.frame[,to.plot]), NMADS)[[madOrient]], col=madOrient), linetype=2) +
            #scale_color_manual(name = "Statistics", values = c(median = "blue", high="red")) +
            scale_fill_brewer(palette = "Set1") +
            #scale_x_log10() +
            xlab(xlabel) +
            ylab(paste0("# cells"))
          plot(p)
          return(p)
  })
  return(plot.list)
})

# violinplots
qc.plots.violin <- lapply(c("Lib.size", "total_features_by_counts", "pct_counts_Mt"), function(to.plot){ 
  if(to.plot=="Lib.size"){
    ylabel <- "Lib. sizes in thousands"
  }else{
    ylabel <- to.plot
  }
  
  plot.list <- lapply(annoFactors, function(separation){
    p <- ggplot(qc.frame, aes_string(separation,to.plot,color=separation))+
      geom_violin() +
      geom_quasirandom() +
      scale_fill_hue(l=40, c=40) +
      ylab(ylabel) +
      xlab(separation) +
      theme(axis.text.x=element_text(angle=45, vjust=1, hjust=1))
    plot(p)
    return(p)
  })
  return(plot.list)
})

```



**Top 2% biggest libraries (based on mapped reads on features)**

```{r top_1perc_cells}

# Output the cells with a library size in the top 2%
highest.lib.size <- colData(sce)[sce$total_counts > quantile(sce$total_counts, 0.98),
              c("total_counts",
               "total_counts_endogenous",
               "total_counts_Mt",
               group.vars)]
highest.lib.size <- highest.lib.size[order(highest.lib.size$total_counts, decreasing = T),]
kable(highest.lib.size,
      format="markdown",
      caption="2% cells with the highest library size")

```

## Count distribution per plate position

The plots below visualise the count data distribution (not log-transformed) via plate position for the categories 'total_features_by_counts_endogenous', 'total_counts' and 'pct_counts_Mt' indicated by spot size. 0-cell and 10-cell controls are indicated in blue and orange, respectively. Symbol shape is defined by custom grouping. For each category the plates are plotted row-wise with plate number in increasing order.

```{r total_counts_per_plate_position, fig.width=8}
##### parameters to set:
# define one category to be used for symbol shape in the plots.
annoFactors <- "pool"
#####

sce$plate_position <- paste0(sce$row, sce$col) # column "plate_position" needed for plotPlatePosition
for (size in c("total_counts", "total_features_by_counts_endogenous", "pct_counts_Mt")) {
cat(paste("Plotting", size, "as spot size\n"))
  plates <- list()
  for (p in as.character(sort(unique(sce$plate)))) {
        plates[[p]] <- scater::plotPlatePosition(sce[, sce$plate==p], colour_by="cells",size_by=size, shape_by=annoFactors,
                            by_exprs_values = "counts", theme_size = 10,  point_alpha = 0.6, point_size = 3, add_legend = F)  
  } # plotPlatePosition uses by_exprs_values = "logcounts" by default. But if not available, uses "counts" instead

  multiplot(plotlist=plates, layout=matrix(c(1:ceiling(length(plates))), ncol=2, byrow=TRUE))
}

```


### Correlation plots for different features

```{r corr_plots}
##### parameters to set:
# define one category to be used for symbol color in the plots.
annoFactors <- "pool"
#####

qc.data <- colData(sce)
qc.data$Lib.Size.million <- qc.data$total_counts/1e6
qc.data <- as.data.frame(qc.data)

if(!is.null(annoFactors)) {annoFactors <- rlang::ensym(annoFactors)} 

lib.size.scatter <- ggplot(qc.data, aes(x=total_features_by_counts, 
                                        y=Lib.Size.million,
                                        color=!!annoFactors)) +
                             geom_point() +
                             scale_color_hue(l=40, c=60) +
                             ylab("Library size (millions)") +
                             xlab("Number of expressed genes")

mit.perc.scatter <- lib.size.scatter + aes(y=pct_counts_Mt) + ylab("% mitochondrial reads")
grid.arrange(lib.size.scatter,  mit.perc.scatter)

```



## Filtering out low quality cells

Filter criteria (see below) are selected according to quality control plots.

Summary of cells that don't pass the QC:

```{r dropout_cells}
##### parameter to set:
# define filtering criteria based on previous QC plots
type_of_threshold = "absolute" # either "absolute" or "relative" (i.e. using MAD)
threshold_total_counts = 2000 # lower threshold 2000
threshold_total_features_by_counts_endogenous = 500 # lower threshold 500
threshold_pct_counts_Mt = 50 # upper threshold 50
NMADS =2 # number of absolute deviations from median. Only relevant if type_of_threshold = "relative".
#####

if(!exists("sce.beforefiltMincount")) {sce.beforefiltMincount <- sce}

# Before we apply QC filters we remove all the cells which hardly have any counts 
min_readcount <- 100
count.drop <- sce$total_counts < min_readcount
cat("We drop ", sum(count.drop), " cells, because they have less than", min_readcount, "reads counted.") 
sce <- sce[,!count.drop]

# apply thresholds
if(type_of_threshold=="absolute") {
  libsize.drop <- sce$total_counts < threshold_total_counts
  feature.drop <- sce$total_features_by_counts < threshold_total_features_by_counts_endogenous
  mito.drop <- sce$pct_counts_Mt > threshold_pct_counts_Mt
  keep <- !(libsize.drop | feature.drop | mito.drop)
  
  qcfailed <- data.frame(criterion=c(paste("total counts <", threshold_total_counts),
                                     paste("total features <", threshold_total_features_by_counts_endogenous),
                                     paste("% mitochondrial counts >", threshold_pct_counts_Mt),
                                     paste("remaining")), 
                         failed=c(sum(libsize.drop), sum(feature.drop), sum(mito.drop), sum(keep)))
  kable(qcfailed, format="markdown", caption="QC filtering") %>% kable_styling()
  
  } else {
    if(type_of_threshold=="relative") {
     libsize.drop <- isOutlier(sce$total_counts, nmads=NMADS, type="lower", log=TRUE)
     feature.drop <- isOutlier(sce$total_features_by_counts, nmads=NMADS, type="lower", log=TRUE) 
     mito.drop <- isOutlier(sce$pct_counts_Mt, nmads=NMADS, type="higher")
     keep <- !(libsize.drop | feature.drop | mito.drop)
  
     qcfailed <- data.frame(criterion=c(paste("total counts <", NMADS, "MAD"),
                                     paste("total features <", NMADS, "MAD"),
                                     paste("% mitochondrial counts >", NMADS, "MAD"),
                                     paste("remaining")), 
                         failed=c(sum(libsize.drop), sum(feature.drop), sum(mito.drop), sum(keep)))
     kable(qcfailed, format="markdown", caption="QC filtering") %>% kable_styling()

  } else {stop("\ntype_of_threshold must be either 'absolute' or 'relative'")}
}
  
qc.drop <- data.frame(libsize=libsize.drop,
                      #libsize.high=libsize.drop.high,
                      feature=feature.drop,
                      mito   = mito.drop,
                      row.names=colnames(sce))
qc.drop <- qc.drop[match(colnames(sce), rownames(qc.drop)), ]  # sort to match the 'sce' cell order
qc.drop$pass <- !apply(qc.drop, 1, any)
```


These quality metrics are summarized in a PCA:

```{r pca1, fig.height=8, fig.width=10}
##### parameters to set:
# define QC metrics to be used for PCA
qcmetrics = c("pct_counts_in_top_100_features", "total_features_by_counts", "pct_counts_feature_control", "total_features_by_counts_feature_control", "log10_total_counts_endogenous", "log10_total_counts_feature_control")
# define one category to be used for symbol shape in the plot.
annoFactors <- "pool"
#####

# prepare PCA from quality metrics
pca.sce <- runPCA(sce, use_coldata=TRUE, selected_variables = qcmetrics) 
pca <- as.data.frame(pca.sce@reducedDims)
rownames(pca) <- rownames(colData(pca.sce)) 
pca <- cbind(pca, qc.drop[match(rownames(pca), rownames(qc.drop)), ])
pca <- cbind(pca, as.data.frame(colData(sce)[match(rownames(pca), colnames(sce)), c(group.vars, "cells")]))

## extract all dropped samples
#df <- subset(pca, libsize | feature | mito | libsize.high)
df <- subset(pca, libsize | feature | mito)
df$libsize.word      <- ifelse(df$libsize==TRUE,"lib size too low","")
#df$libsize.high.word <- ifelse(df$libsize.high==TRUE,"lib size too high","")
df$feature.word      <- ifelse(df$feature==TRUE,"genes detected","")
df$mito.word         <- ifelse(df$mito==TRUE,"Mt fraction","")

df$rm      <- paste(df$libsize.word,df$feature.word,df$mito.word,sep="+")
df$rm.nice <- sub("^\\+","",sub("\\+$","",gsub("\\+\\+","\\+",df$rm)))
df.kept <- subset(pca, !(libsize | feature | mito))

if(!is.null(annoFactors)) {annoFactors.name <- rlang::ensym(annoFactors)} else {
  annoFactors.name <- NULL}
  
plotReducedDim(pca.sce, use_dimred="PCA_coldata", by_exprs_values = "counts", shape_by=annoFactors) +
  geom_point(data=df, aes(x=PC1, y=PC2, color=rm.nice, shape=!!annoFactors.name), size=3)+
  geom_point(data=df.kept, aes(x=PC1, y=PC2, color="kept", shape=!!annoFactors.name), size=3) +
  geom_text_repel(aes(x=PC1, y=PC2, label=cells), subset(pca, cells %in% c("0c", "10c")), color="grey30", size=6) +
  scale_color_manual("QC drop", 
                     values=c("grey50","#E41A1C","#377EB8","#4DAF4A","#FF7F00","#984EA3","#FFFF33","#A65628","#F781BF"), 
                     guide="legend")+
  theme_bw()


```




Removed samples/cells:

```{r remove_low_qual_cells_and_control_wells}
##### parameters to set:
# define up to 2 categories to be used for output tables.
annoFactors <- c("group", "pool")
#####

if(!exists("sce.before.QCfilt")) {sce.before.QCfilt <- sce}

# output overview of remaining cells and table of removed cells
j <- c("total_counts", "total_features_by_counts", "pct_counts_Mt", annoFactors) 
x <- cbind(qc.drop, colData(sce)[match(rownames(qc.drop), rownames(colData(sce))), j])
# knitr::kable(as.data.frame(apply(qc.drop, 2, sum)), col.names="cells", caption="")
x$pct_counts_Mt   <- round(x$pct_counts_Mt  , digits=2) 
x <- as.data.frame(x)
DT::datatable(x[!x$pass, ])

# filter out cells failing QC
if(length(qc.drop$pass) == ncol(sce)) { # if block is executed multiple times
sce <- sce[, qc.drop$pass]
}

# overview of remaining cells after QC filtering
knitr::kable(table(colData(sce)[, annoFactors, drop=F]), col.names=c(annoFactors, "cell count"), caption="Amount of cells remaining after QC filtering") %>% kable_styling()

# filter out control wells with 0 or 10 cells
sce <- sce[, colData(sce)$cells == "1c"]
sce$wells <- gsub("_S[0-9]+$", "", gsub("_1c", "", colnames(sce)))

# overview of remaining cells after removing control wells 
knitr::kable(table(colData(sce)[, annoFactors, drop=F]), col.names=c(annoFactors, "cell count"), caption="Amount of cells remaining after filtering for control wells (0c/10c)") %>% kable_styling() 

```


### Replotting the PCA after filtering

```{r pca2, fig.height=6, fig.width=8}
##### parameters to set:
# define up to 2 categories to be indicated in the PCA plot by color and shape.
annoFactors <- c("group", "pool")
#####

plotPCAfromQCmetrics(sce, qcmetrics, anno=annoFactors)
```



## Filtering out low abundance genes

Low abundance genes are likely to be dominated by drop-out events (Poisson noise in different cells). They do not contain enough information for statistical inference, and may compromise accuracy of continuous approximations when fitting the data (edgeR BCV estimation).

Average counts per gene should correlate with number of cells expressing it:

```{r remove_low_abundance_genes}
avg.counts <- calcAverage(sce, use_size_factors=F) 
expressed.cells <- nexprs(sce, byrow=TRUE)   # number of cells expressing the gene
smoothScatter(log10(avg.counts), expressed.cells,
              xlab=expression("Log10 average count"), ylab= "Number of expressing cells")

```

## Top most highly expressed genes

The plot below shows the most highly expressed genes (based on un-normalized mean counts). All mitochondrial genes are marked as "Feature control". The color represents the total number of expressed genes in the respective sample/cell.

```{r highly_expr_genes, fig.height=6, fig.width=6}
# use tmp.sce for plotting with different rownames
tmp.sce <- sce
rownames(tmp.sce) <- rowData(sce)$SYMBOL
fontsize <- theme(axis.text=element_text(size=6), axis.title=element_text(size=10))
plotQC(tmp.sce, type = "highest-expression", n=50) + fontsize
rm(tmp.sce)
```


# Normalization of cell-specific biases
Normalization is required to eliminate these cell-specific differences in capture efficiency, prior to downstream quantitative analyses.

## Normalization for library size

Size factors can be calculated with DESeq2 or edgeR, but these methods do not work well with single-cell data due to the dominance of low and zero counts. To overcome this, we use the method from Lun et al. (2016) implemented in the *cran* package, which pools counts from many cells to estimate the size factors and to finally deconvolute them to cell-specific factors. Finally, normalized log2-expression values are computed for each endogenous gene using the appropriate size factors.

```{r size_factors_and_normalize, warning=FALSE, message=FALSE}
##### parameters to set:
# define up to 2 categories to be indicated in the plot by color and shape.
annoFactors <- c("group", "pool")
#####

if(!exists("sce.nonorm")) {sce.nonorm <- sce}
high.ave <- rowData(sce)$ave.count >= 0.1

cat("\nSummary size factors")
sce <- computeSumFactors(sce, sizes=seq(21, 101, 5))
summary(sizeFactors(sce))

# cat("\nSummary size factors for ERCC spike-ins\n")
# sce <- computeSpikeFactors(sce, type="ERCC", general.use=F) ## general.use=TRUE use spike-ins for normalisation
# summary(sizeFactors(sce, "ERCC"))

# plot size factors 
 if(length(annoFactors)>2) {stop("\nno more than 2 categories allowed in 'annoFactors'.")}
  dotcol <- annoFactors[1]
  dotcol <- rlang::ensym(dotcol)
  if(length(annoFactors)==2) { 
    dotshape <- annoFactors[2]
    dotshape <- rlang::ensym(dotshape)
    } else {
      dotshape <- NULL}

to.plot <- data.frame(sizeFactors=sizeFactors(sce),
                 total_counts=sce$total_counts/1e6,
                 colData(sce)[,annoFactors])
ggplot(to.plot, aes(x=sizeFactors, 
                    y=total_counts,
                    color=!!dotcol, shape=!!dotshape))+
  geom_point()+ ylab("Library size (millions)") + scale_color_hue(l=40, c=40)

# normalise
sce <- normalize(sce) # adds normalized logcounts matrix
```


### Normalized log2-expression of top50 genes with highest average expression:

```{r plot_violin_top50, fig.width=12, fig.height=10}
##### parameters to set:
# define up to 2 categories to be indicated in the plot by color and shape.
annoFactors <- c("group", "pool")
#####

# use tmp.sce to change rownames to SYMBOL for the plot
tmp.sce <- sce
rownames(tmp.sce) <- rowData(sce)$SYMBOL

# re-calculate averages, using newly determined size factors
ave.counts.new <- calcAverage(tmp.sce)
rowData(tmp.sce)$ave.count.new <- ave.counts.new

top.sce.aver.size <- head(rowData(tmp.sce)[order(rowData(tmp.sce)$ave.count.new,decreasing=TRUE),],50)

if(length(annoFactors)>2) {stop("\nno more than 2 categories allowed in 'annoFactors'.")}
  dotcol <- annoFactors[1]
  if(length(annoFactors)==2) { 
    dotshape <- annoFactors[2]} else {
      dotshape <- NULL}

plotExpression(tmp.sce, top.sce.aver.size$SYMBOL[1:25], colour_by=dotcol, shape_by = dotshape) + ggtitle("highest avg. expression 1:25")
plotExpression(tmp.sce, top.sce.aver.size$SYMBOL[26:50], colour_by=dotcol, shape_by = dotshape) + ggtitle("highest avg. expression 26:50")


```


## Checking for confounding factors ##

### Identify explanatory variables ##

We check whether there are technical factors that contribute substantially to the heterogeneity of gene expression. If so, the factor may need to be regressed out to ensure that it does not inflate the variances or introduce spurious correlations.

```{r explanatorx_variables, echo=F, error=F, warning=F, message=F}
##### parameters to set:
# define potential explanatory variables to be tested for their effect
explanatoryVariables <- c("plate", "group", "log10_total_counts")
#####

plotExplanatoryVariables(sce, variables=explanatoryVariables, exprs_values = "logcounts") + fontsize

```




### Classification and normalization of cell cycle phase

We use the prediction method described by Scialdone et al. (2015) to classify cells into cell cycle phases based on the gene expression data. Pre-trained classifiers are available in scran for human and mouse data. 

```{r find_cell_cycle, fig.width=8, fig.height=8}
##### parameters to set:
# define organism (either "human" or "mouse")
org ="mouse"
# define one category to be used for symbol colour in the plot.
annoFactors <- "group"
#####

if(!exists("sce.no.ccp")) {sce.no.ccp <- sce}
set.seed(100)

# load mm.pairs: "mouse_cycle_markers.rds" or "human_cycle_markers.rds"
mm.pairs <- readRDS(system.file("exdata", paste0(org, "_cycle_markers.rds"), package="scran")) # mouse_cycle_markers.rds

# determine cell cycle phase:
# in "human_cycle_markers.rds" ensembl names are without the ".number" at the very end, but 
# the rownames of our sce object include this. ---> remove .number
assignments <- cyclone(sce, pairs=mm.pairs, gene.names=sub("\\..*$","",rowData(sce)$ENSEMBL), assay.type="logcounts") 
sce$phases <- assignments$phases
cat("\ncell cycle phases")
table(sce$phases)
plot(0, xlim=c(0, 1), ylim=c(0, 1), type="n", xlab="G1 score", ylab="G2/M score")
points(assignments$scores$G1, assignments$scores$G2M, col=scales::alpha(pal[factor(colData(sce)[,annoFactors])], .5) )   # pch=16
# abline(h=.5, v=.5, lty=2, col="red")
arrows(0.5,0.5,1,1, length=0, col="red", lty=2)
arrows(0,0.5,0.5,0.5, length=0, col="red", lty=2)
arrows(0.5,0,0.5,0.5, length=0, col="red", lty=2)

text(x=c(.25, .75, .25, .75), y=c(.75, .75, .25, .25), labels=c("G2", " ", "S", "G1"))
legend("bottomleft", col=c(pal[1:4]), pch=16, legend=c(levels(factor(colData(sce)[,annoFactors]))))

```

Cells are classified as being in G1 phase if the G1 score is above 0.5 and greater than the G2/M score; in G2/M phase
if the G2/M score is above 0.5 and greater than the G1 score; and in S phase if neither score is above 0.5. 

We also have to account for possible cell cycle effect on downstream analysis, using the G1 and G2M assignment scores as a continuous blocking factor to estimate the variance. This is more graduated than using a strict assignment of each cell to a specific phase, as the magnitude of the score considers the uncertainty of the assignment. The phase covariates in the design matrix will absorb any phase-related effects on expression such that they will not affect estimation of the effects of other experimental factors. 

```{r blocking_on_the_cell_cycle_phase}
# adjust for cell cycle phase vy modelling G scores
design <- model.matrix(~ G1 + G2M, assignments$score)
fit.block <- trendVar(sce, design=design, parametric=TRUE, use.spikes=F)
dec.block <- decomposeVar(sce, fit.block)

sce.no_block <- sce

assay(sce, "corrected") <- removeBatchEffect(logcounts(sce), covariates=design[,-1])

sce <- denoisePCA(sce, technical=dec.block, assay.type="corrected")

sce.no_block$G1score <- sce$G1score <- assignments$score$G1
sce.no_block$G2Mscore <- sce$G2Mscore <- assignments$score$G2M

# Without blocking on phase score.
fit <- trendVar(sce.no_block, parametric=TRUE, use.spikes=F) 
sce.no_block <- denoisePCA(sce.no_block, technical=fit$trend)
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
out <- plotReducedDim(sce.no_block, use_dimred="PCA", ncomponents=2, colour_by="G1score", 
    size_by="G2Mscore") + fontsize + ggtitle("Before removal")

# After blocking on the phase score.
out2 <- plotReducedDim(sce, use_dimred="PCA", ncomponents=2,  
    colour_by="G1score", size_by="G2Mscore") + fontsize + ggtitle("After removal")
multiplot(out, out2, cols=2)

#### switch assay channel for downstream processing
assay(sce, "logcounts_not_ccp_corrected") <- assay(sce, "logcounts")
assay(sce, "logcounts") <- assay(sce, "corrected")
assay(sce, "corrected") <- NULL

```


# Identifying highly variable genes (HVGs)

Estimation of the variance in expression for each gene, followed by decomposition of the variance into biological and technical components. The technical component would be estimated by fitting a mean-variance trend to the spike-in transcripts using the trendVar function. The biological component of the variance can then be calculated by subtracting the technical component from the total variance of each gene with the decomposeVar function.

```{r trendVar, echo=F, error=F, warning=F, message=F}
# estimate highly variable genes
decVar.list <- lapply(c("all"), function(type){ # no subsetting of cell groups
    sce.tmp <- sce
    var.fit <- trendVar(sce.tmp, method="loess",
                    loess.args=list(span=0.3),
                    use.spikes=F)
decVar <- decomposeVar(sce.tmp, var.fit)
 return(list(decVar=decVar, var.fit=var.fit))
})
names(decVar.list) <- c("all")

```


The scatter plot below shows the mean log expression vs. the total variance, while the blue line shows the technical part of the variance.

```{r plot_trendVar, echo=F, error=F, warning=F, message=F}
# plot mean log expression vs. the total variance
for(to.plot in names(decVar.list)){
  decVar.tmp <- decVar.list[[to.plot]]$decVar 
  var.fit.tmp <- decVar.list[[to.plot]]$var.fit 
  plot(decVar.tmp$mean, decVar.tmp$total, pch=16, cex=0.6, col="#00000050", xlab="Mean log-expression", ylab="Variance of log-expression", main=paste("Plot for", to.plot, "cells"))
#cur.spike <- isSpike(sce, type="ERCC")
#points(decVar.tmp$mean[cur.spike], decVar.tmp$total[cur.spike], col="red", pch=16)
o <- order(decVar.tmp$mean)
lines(decVar.tmp$mean[o], decVar.tmp$tech[o], col="dodgerblue", lwd=2)
}

```

HVGs are defined as genes with biological components that are significantly greater than zero at a false discovery rate (FDR) of 5%. We only consider a gene to be a HVG if it has a biological component greater or equal than 0.5 (assuming the log-expression values are normally distributed with a variance of 0.5, this means an average difference of 2-fold between 2 cells).

The number of HVGs found is:

```{r get_hvg, fig.width=11, echo=F, error=F, warning=F, message=F}
##### parameters to set:
# define up to 2 categories to be indicated in the plot by color and shape.
annoFactors <- c("group", "pool")
#####


# count number of HVGs
hvg.list <- lapply(names(decVar.list), function(x){
  decVar <- decVar.list[[x]]$decVar
hvg <- decVar[which(decVar$FDR <= 0.05 & decVar$bio >= 0.5), ]
hvg <- hvg[order(hvg$bio, decreasing=TRUE), ]
cat("Number of HVGs for", x, "cells:", nrow(hvg), "\n")
cat("\n")
return(hvg)
})
names(hvg.list) <- names(decVar.list)

# plot top 10 HVGs
if(length(annoFactors)>2) {stop("\nno more than 2 categories allowed in 'anno'.")}
  dotcol <- annoFactors[1]
  if(length(annoFactors)==2) { 
    dotshape <- annoFactors[2]} else {
      dotshape <- NULL}

for(type in names(hvg.list)){
  hvg <- hvg.list[[type]]
  if(type=="all"){
    tmp.sce <- sce
  }else{
   tmp.sce <- sce[,sce$type==type] # if desired to subset this plot for subgroups of cells
  }
    rownames(tmp.sce) <- rowData(tmp.sce)$SYMBOL
    if(type=="all"){
    plot(
      plotExpression(tmp.sce, 
                     na.omit(gtf$gene_name[match(rownames(hvg), gtf$gene_id)])[1:10],
                     colour_by=dotcol,
                     shape_by=dotshape) + 
        ggtitle("Top 10 HGVs for all cells") +
        scale_color_hue(c=40, l=50, name="plate") +
        facet_grid(~colour_by))
    
      }else{ # if it desired later to subset this plot for subgroups of cells
      
    plot(plotExpression(tmp.sce, 
                        na.omit(gtf$gene_name[match(rownames(hvg), gtf$gene_id)])[1:10],
                        colour_by=dotcol,
                        shape_by=dotshape) +
           scale_fill_hue(c=40, l=50, name=dotcol)+ 
           ggtitle(paste("10 highest HGVs for", type)))
    
    }
}
```

## Identify correlated HVGs ###

Another useful procedure is to identify the HGVs that are highly correlated with one another. This distinguishes between HVGs caused by random noise and those involved in driving systematic differences between sub-populations. Correlations between genes are quantified by computing Spearman's rho, which accomodates non-linear relationships in the expression value. Gene pairs with significantly large positive or negative values of rho are identified using the correlatePairs function. 

```{r get_hvg_corr, echo=F, error=F, warning=F, message=F}
# Identify correlated HVGs
set.seed(100)

hvg.cor.list <- lapply(names(hvg.list), function(type){
  if(type=="all"){
    tmp.sce <- sce
  }else{
    tmp.sce <- sce[, sce$type == type]
  }
  hvg.cor <- correlatePairs(tmp.sce, subset.row=rownames(hvg.list[[type]] ))

  hvg.cor$gene1SYMBOL <- gtf$gene_name[match(hvg.cor$gene1, gtf$gene_id)]
  hvg.cor$gene2SYMBOL <- gtf$gene_name[match(hvg.cor$gene2, gtf$gene_id)]
  #write.table(file=paste0(SHINYREPS_PREFIX,type, "_hvg_corr.tsv"), hvg.cor, sep="\t", quote=FALSE, row.names=FALSE)
  return(list(hvg.cor=hvg.cor, sig.cor=hvg.cor$FDR <= .05)
  )
})
names(hvg.cor.list) <- names(hvg.list)


```


# Using correlated HVGs for further data exploration

## PCA based on significantly correlated HVGs:

```{r hvg_pca, echo=F, error=F, warning=F, message=F}
##### parameters to set:
# define up to 2 categories to be indicated in the plot by color and shape.
annoFactors <- c("pool", "group") # 
#####


if(length(annoFactors)>2) {stop("\nno more than 2 categories allowed in 'annoFactors'.")}
  dotcol <- annoFactors[1]
  if(length(annoFactors)==2) { 
    dotshape <- annoFactors[2]} else {
      dotshape <- NULL}

# plot PCA
hvg.cor.names <- names(hvg.cor.list)
hvg.cor.list <- lapply(names(hvg.cor.list), function(type){
  hvg.cor <- hvg.cor.list[[type]]$hvg.cor
  sig.cor <- hvg.cor.list[[type]]$sig.cor
  top.hvg    <- unique(c(hvg.cor$gene1[sig.cor], hvg.cor$gene2[sig.cor]))
  cat(paste("number of genes part of min 1 significant correlation:", length(top.hvg), "\n"))
  if(type=="all"){
    sce.tmp <- sce
  p <- plotPCA(sce.tmp, rerun = T, 
        colour_by=dotcol, shape_by = dotshape, point_size=3,
        run_args=list(ntop=nrow(sce.tmp), feature_set=top.hvg)) +  # feature_set overwrites ntop
         # scale_color_hue(c=40, l=50, name=dotcol) +
    ggtitle(paste("PCA of top correlated HVGs"))

  }else{
    sce.tmp <- sce[, sce$type==type]
    p <- plotPCA(sce.tmp, rerun = T, 
        colour_by=dotcol, shape_by = dotshape, point_size=3,
        run_args=list(ntop=nrow(sce.tmp), feature_set=top.hvg)) +  
         # scale_color_hue(c=40, l=50, name=dotcol) +
    ggtitle(paste("PCA of top highly correlated genes", type, "group"))

  }
  return(list(top.hvg = top.hvg,
              hvg.cor = hvg.cor,
              sig.cor = sig.cor,
              cor.plot = p))
})
names(hvg.cor.list) <- hvg.cor.names
for(type in names(hvg.cor.list)){
  plot(hvg.cor.list[[type]]$cor.plot)
}

```

## Identification of sub-populations with t-SNE ###

Another widely used approach is the t-stochastic neighbour embedding (t-SNE) method (Van der Maaten & Hinton, 2008). t-SNE  tends  to  work  better  than  PCA  for  separating  cells  in  more  diverse  populations.  This  is  because  the former can directly capture non-linear relationships in high-dimensional space, whereas the latter must represent them (suboptimally) as linear components. However, this improvement comes at the cost of more computational effort and complexity. In particular, 
t-SNE is a stochastic method, so users should run the algorithm several times to ensure that the results are representative, and then set a seed to ensure that the chosen results are reproducible. It is also advisable to test different settings of the “perplexity” parameter as this will affect the distribution of points in the low-dimensional space.

The perplexity can be interpreted as a smooth measure of the effective number of neighbors. The performance of SNE is fairly robust to changes in the perplexity, and typical values are between 5 and 50. 

A major weakness of t-SNE is that the cost function is not convex, as a result of which several optimization parameters need to be chosen. The constructed solutions depend on these choices of optimization parameters and may be different each time t-SNE is run from an initial random configuration of map points. But the developers of t-SNE have demonstrated that the same choice of optimization parameters can be used for a variety of different visualization tasks and found that the quality of the optima does not vary much from run to run. Thus, t-SNE should not be rejected in favor of methods that lead to convex optimization problems but produce noticeably worse visualizations. A local optimum of a cost function that accurately captures what is wanted in a visualization is often preferable to the global optimum of a cost function that fails to capture important aspects of what is wanted.

Identification of sub-populations with t-SNE, trying different perplexity values to identify structure based on the sig. correlated HVG genes:

```{r plot_various_perplexities, fig.height=5, fig.width=10, echo=F, error=F, warning=F, message=F}
##### parameters to set:
# define up to 2 categories to be indicated in the plot by color and shape.
annoFactors <- c("group", "pool")
#####

if(length(annoFactors)>2) {stop("\nno more than 2 categories allowed in 'annoFactors'.")}
  dotcol <- annoFactors[1]
  if(length(annoFactors)==2) { 
    dotshape <- annoFactors[2]} else {
      dotshape <- NULL}

# t-SNE plots without using pre-existing PCA results as input

for(type in names(hvg.cor.list)){
  top.hvg <- hvg.cor.list[[type]]$top.hvg

  if(type=="all"){
    sce.tmp <- sce
  do.call(multiplot, c(mclapply(c(5, 10), function(p) {

    plotTSNE(sce.tmp,  rerun = T, 
             colour_by=dotcol, shape_by=dotshape,
             run_args=list(perplexity=p,
                           rand_seed=100, ntop=nrow(sce.tmp), # feature_set overwrites ntop
                           feature_set=top.hvg)) +
      ggtitle(paste("t-SNE plot of top correlated HVGs with perplexity", p))
  }, mc.cores=1), cols=2))
  }else{
    sce.tmp <- sce[, sce$type==type]
  do.call(multiplot, c(mclapply(c(3, 5), function(p) {
    plotTSNE(sce.tmp, rerun = T, # FR add rerun = T
             colour_by=dotcol, shape_by=dotshape,
             run_args=list(perplexity=p,
                           rand_seed=100, ntop=nrow(sce.tmp), # feature_set overwrites ntop
                           feature_set=top.hvg)) +
      ggtitle(paste("group:", type, "with perplexity", p))
  }, mc.cores=1), cols=2))
  }
}


```


### Identification of sub-populations with UMAP ###

Identification of sub-populations with UMAP plots (uniform manifold approximation and projection) to identify structure based on the sig. correlated HVG genes:

```{r UMAP_plot, fig.height=5, fig.width=10, echo=F, error=F, warning=F, message=F}
##### parameters to set:
# define up to 2 categories to be indicated in the plot by color and shape.
annoFactors <- c("group", "pool")
#####

if(length(annoFactors)>2) {stop("\nno more than 2 categories allowed in 'annoFactors'.")}
  dotcol <- annoFactors[1]
  if(length(annoFactors)==2) { 
    dotshape <- annoFactors[2]} else {
      dotshape <- NULL}

for(type in names(hvg.cor.list)){
  top.hvg <- hvg.cor.list[[type]]$top.hvg
  
  if(type=="all"){
    sce.tmp <- sce

  umap1 <- plotUMAP(sce.tmp,  rerun = T, 
             colour_by=dotcol, shape_by=dotshape,
             run_args=list(rand_seed=100, 
                           ntop=nrow(sce.tmp) # ntop default is 500
                           )) +  
      ggtitle(paste("UMAP of all genes"))
    
  umap2 <- plotUMAP(sce.tmp, rerun = T, 
             colour_by=dotcol, shape_by=dotshape,
             run_args=list(rand_seed=100, ntop=nrow(sce.tmp), 
                           feature_set=top.hvg)) + # feature_set overwrites ntop
      ggtitle(paste("UMAP of cor HVGs"))
    
    multiplot(umap1, umap2, cols=2)

  }else{
    sce.tmp <- sce[, sce$type==type]

   umap1 <- plotUMAP(sce.tmp, rerun = T, 
             colour_by=dotcol, shape_by=dotshape,
             run_args=list(rand_seed=100, 
                           ntop=nrow(sce.tmp) # ntop default is 500
                           )) +  
      ggtitle(paste("UMAP of all genes for group:", type))
    
   umap2 <-   plotUMAP(sce.tmp, rerun = T, 
             colour_by=dotcol, shape_by=dotshape,
             run_args=list(rand_seed=100, ntop=nrow(sce.tmp), 
                           feature_set=top.hvg)) + # feature_set overwrites ntop
      ggtitle(paste("UMAP of cor HVGs for group:", type))
   
       multiplot(umap1, umap2, cols=2)

  }
}

```


</div>






























